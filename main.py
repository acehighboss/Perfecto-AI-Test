# main.py

import os
import traceback
import streamlit as st
from typing import List, Any

# LangChain types
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document

# ---- Repo ë‚´ë¶€ ëª¨ë“ˆ (ì¡´ì¬ ê°€ì •) ----
# robust URL ìˆ˜ì§‘ê¸° (JS ë Œë”ë§ í† ê¸€ í¬í•¨) - file_handler.pyì— êµ¬í˜„ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
from file_handler import get_documents_from_urls_robust

# RAG íŒŒì´í”„ë¼ì¸ (ê¸°ì¡´ ë ˆí¬ì˜ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì‚¬ìš©)
# - get_retriever_from_source(documents=[...], ...) -> retriever
# - get_conversational_rag_chain(retriever=retriever) -> chain
from RAG.rag_pipeline import (
    get_retriever_from_source,
    get_conversational_rag_chain,
)

# ------------------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# ------------------------------------
st.set_page_config(page_title="Perfecto AI Test (RAG)", page_icon="ğŸ§ª", layout="wide")
st.title("Perfecto AI Test (RAG)")

# ------------------------------------
# Session State ì´ˆê¸°í™”
# ------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages: List[Any] = []
if "docs" not in st.session_state:
    st.session_state.docs: List[Document] = []
if "ready_to_analyze" not in st.session_state:
    st.session_state.ready_to_analyze = False

# ------------------------------------
# Sidebar (URL ì—…ë¡œë“œ + ì˜µì…˜)
# ------------------------------------
with st.sidebar:
    st.subheader("URL ì—…ë¡œë“œ")
    url_input = st.text_area(
        "í•˜ë‚˜ ì´ìƒì˜ URLì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”",
        value="https://www.mobiinside.co.kr/2025/06/27/ai-news-3/\nhttps://namu.wiki/w/%EC%84%B1%EA%B2%BD",
        height=120,
        help="ì˜ˆ: ê° ì¤„ì— 1ê°œ URL",
    )

    # í¬ë¡¤ë§ ë™ì‘ í† ê¸€
    respect_robots = st.toggle(
        "robots.txt ì¤€ìˆ˜", value=True,
        help="í•´ì œ ì‹œ ì°¨ë‹¨ ê²½ë¡œë„ ì‹œë„í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ì„œë²„ ë‹¨ì—ì„œ ê±°ë¶€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    use_js_render = st.toggle(
        "JS ë Œë”ë§(Playwright) ì‚¬ìš©", value=False,
        help="React/Vue ë“± CSR í˜ì´ì§€ ëŒ€ì‘. ëŠë¦¬ê³ , í˜¸ìŠ¤íŒ… í™˜ê²½ì— ë”°ë¼ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    js_only_when_needed = st.toggle(
        "ì •ì  ì¶”ì¶œ ì‹¤íŒ¨/ë¶€ì¡± ì‹œì—ë§Œ JS ì‚¬ìš©", value=True,
        help="ì •ì  íŒŒì‹±ìœ¼ë¡œ ì¶©ë¶„í•˜ë©´ JS ë Œë”ë§ì„ ìƒëµí•˜ì—¬ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤."
    )

    # ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼
    if st.button("URL ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True):
        urls = [u.strip() for u in url_input.splitlines() if u.strip()]
        try:
            docs = get_documents_from_urls_robust(
                urls,
                respect_robots=respect_robots,
                use_js_render=use_js_render,
                js_only_when_needed=js_only_when_needed,
            )
            st.session_state.docs = docs
            st.session_state.ready_to_analyze = len(docs) > 0

            if not docs:
                st.warning(
                    "ë³¸ë¬¸ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. (robots ì°¨ë‹¨/ë¡œê·¸ì¸ í•„ìš”/ê°•í•œ ë´‡ì°¨ë‹¨/JS ë¯¸ì§€ì› í™˜ê²½/ë¹ˆ ë³¸ë¬¸ ë“±)"
                )
            else:
                st.success(f"{len(docs)}ê°œ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"URL ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.caption(traceback.format_exc())
            st.session_state.docs = []
            st.session_state.ready_to_analyze = False

    st.divider()

    # ë¶„ì„ ìš”ì²­ í”„ë¡¬í”„íŠ¸
    user_query = st.text_input(
        "ì§ˆë¬¸/ë¶„ì„ ìš”ì²­",
        value="ë‘ ë¬¸ì„œì˜ í•µì‹¬ ìš”ì•½, ê³µí†µì /ì°¨ì´, ì£¼ì˜í•  ì ì„ ì•Œë ¤ì¤˜. ì¶œì²˜ë„ í‘œì‹œí•´ì¤˜."
    )

    # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
    analyze_clicked = st.button(
        "ë¶„ì„ ì‹œì‘",
        type="primary",
        use_container_width=True,
        disabled=not st.session_state.ready_to_analyze
    )

# ------------------------------------
# ë³¸ë¬¸ ë ˆì´ì•„ì›ƒ
# ------------------------------------
col_chat, col_right = st.columns([3, 2])

# ------------------------------------
# ì¢Œì¸¡: ëŒ€í™”/ë¶„ì„
# ------------------------------------
with col_chat:
    st.subheader("ëŒ€í™”")

    # ê¸°ì¡´ ë©”ì‹œì§€ ë Œë”
    for m in st.session_state.messages:
        if isinstance(m, HumanMessage):
            st.chat_message("user").write(m.content)
        elif isinstance(m, AIMessage):
            st.chat_message("assistant").write(m.content)
        else:
            # ì•ˆì „ì¥ì¹˜(ë¬¸ìì—´ ë“±)
            role = "assistant" if isinstance(m, dict) and m.get("role") == "assistant" else "user"
            st.chat_message(role).write(str(m))

    # ë¶„ì„ ì‹œì‘ ë¡œì§
    if analyze_clicked and st.session_state.ready_to_analyze and st.session_state.docs:
        st.session_state.messages.append(HumanMessage(content=user_query))
        try:
            # 1) ë¬¸ì„œ â†’ retriever
            retriever = get_retriever_from_source(
                documents=st.session_state.docs,  # <- ë°˜ë“œì‹œ documents ì¸ìë¥¼ ë°›ë„ë¡ rag_pipeline ìˆ˜ì •ë˜ì–´ ìˆì–´ì•¼ í•¨
                # í•„ìš” ì‹œ chunk_size, chunk_overlap ë“±ì˜ íŒŒë¼ë¯¸í„°ë„ ì „ë‹¬ ê°€ëŠ¥
            )

            # 2) retriever â†’ ëŒ€í™”í˜• RAG ì²´ì¸
            chain = get_conversational_rag_chain(retriever=retriever)

            # 3) í˜¸ì¶œ
            with st.spinner("ë¶„ì„ ì¤‘..."):
                result = chain.invoke({"question": user_query})

            # 4) ì‘ë‹µ/ì¶œì²˜ ì²˜ë¦¬ (ì²´ì¸ êµ¬í˜„ë³„ë¡œ ìœ ì—°í•˜ê²Œ ìˆ˜ìš©)
            answer_text = None
            source_docs: List[Document] = []

            # (A) resultê°€ dict í˜•íƒœë¡œ answer / source_documentsë¥¼ ì œê³µí•˜ëŠ” ê²½ìš°
            if isinstance(result, dict):
                answer_text = result.get("answer") or result.get("output") or result.get("text")
                sd = result.get("source_documents") or result.get("sources") or []
                if isinstance(sd, list):
                    # LangChain Document íƒ€ì… ë˜ëŠ” ìœ ì‚¬ dictë¥¼ í—ˆìš©
                    for d in sd:
                        if isinstance(d, Document):
                            source_docs.append(d)
                        elif isinstance(d, dict) and "page_content" in d:
                            # dict -> Document ë³€í™˜
                            md = d.get("metadata", {}) or {}
                            source_docs.append(Document(page_content=d["page_content"], metadata=md))
            # (B) ë‹¨ìˆœ ë¬¸ìì—´ë¡œ ì˜¤ëŠ” ê²½ìš°
            if answer_text is None and isinstance(result, str):
                answer_text = result

            # 5) ë‹µë³€ ë Œë”
            if not answer_text:
                answer_text = "ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸/ë¬¸ì„œ ìƒíƒœë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."

            st.chat_message("assistant").write(answer_text)
            st.session_state.messages.append(AIMessage(content=answer_text))

            # 6) ìš°ì¸¡ ì»¬ëŸ¼ì˜ 'ì°¸ê³ /ì¶œì²˜' ì„¹ì…˜ì´ source_documentsë¥¼ ë Œë”í•  ìˆ˜ ìˆë„ë¡ ìƒíƒœ ì €ì¥
            #    (ì—¬ê¸°ì„  docs ì „ì²´/í˜¹ì€ source_documents ìš°ì„ )
            if source_docs:
                # source_documentsê°€ ìˆìœ¼ë©´ ê·¸ê²ƒ ìš°ì„  ë¯¸ë¦¬ë³´ê¸°ë¡œ í‘œì‹œí•  ìˆ˜ ìˆë„ë¡ êµì²´
                st.session_state.docs_for_citation = source_docs
            else:
                st.session_state.docs_for_citation = st.session_state.docs

            # ë‹¤ìŒ í´ë¦­ ì „ê¹Œì§€ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
            st.session_state.ready_to_analyze = False

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.caption(traceback.format_exc())
            # ì‹¤íŒ¨ ì‹œ ready í”Œë˜ê·¸ëŠ” ìœ ì§€í•˜ì—¬ ì¬ì‹œë„ ê°€ëŠ¥í•˜ë„ë¡ ë‘˜ ìˆ˜ë„ ìˆìŒ
            # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ Falseë¡œ ì´ˆê¸°í™”
            st.session_state.ready_to_analyze = False

# ------------------------------------
# ìš°ì¸¡: ì†ŒìŠ¤ ë¯¸ë¦¬ë³´ê¸° & ì°¸ê³ /ì¶œì²˜
# ------------------------------------
with col_right:
    st.subheader("ì†ŒìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
    preview_docs = st.session_state.get("docs_for_citation") or st.session_state.docs
    if preview_docs:
        for i, d in enumerate(preview_docs, 1):
            src = (d.metadata or {}).get("source", "")
            title = (d.metadata or {}).get("title", src or f"ë¬¸ì„œ {i}")
            with st.expander(f"[{i}] {title}"):
                if src:
                    st.caption(src)
                body = d.page_content or ""
                st.write(body[:1200] + ("..." if len(body) > 1200 else ""))  # ê¸¸ì´ ì œí•œ

    st.subheader("ì°¸ê³ /ì¶œì²˜")
    if preview_docs:
        # ì¤‘ë³µ URL ì œê±°í•˜ì—¬ ë‚˜ì—´
        seen = set()
        for d in preview_docs:
            src = (d.metadata or {}).get("source") or ""
            title = (d.metadata or {}).get("title") or src
            key = (title, src)
            if src and key not in seen:
                seen.add(key)
                st.markdown(f"- [{title}]({src})")
    else:
        st.caption("ë¶ˆëŸ¬ì˜¨ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ URLì„ ì…ë ¥í•˜ê³  â€˜URL ë¶ˆëŸ¬ì˜¤ê¸°â€™ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
