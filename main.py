import os
import traceback
import streamlit as st
from typing import List, Any
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document

# ---- ë‚´ë¶€ ëª¨ë“ˆ ----
from file_handler import (
    get_documents_from_urls_robust,
    get_documents_from_uploaded_files
)
from RAG.rag_pipeline import (
    get_retriever_from_source,
    get_conversational_rag_chain,
)

# ------------------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# ------------------------------------
st.set_page_config(page_title="Perfecto AI Test (RAG)", page_icon="ðŸ§ª", layout="wide")
st.title("Perfecto AI Test (RAG)")

# ------------------------------------
# Session State ì´ˆê¸°í™”
# ------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages: List[Any] = []
if "docs" not in st.session_state:
    st.session_state.docs: List[Document] = []
if "ready_to_analyze" not in st.session_state:
    st.session_state.ready_to_analyze = False
if "docs_for_citation" not in st.session_state:
    st.session_state.docs_for_citation: List[Document] = []

# ------------------------------------
# Sidebar (URL + íŒŒì¼ ì—…ë¡œë“œ + ì˜µì…˜)
# ------------------------------------
with st.sidebar:
    st.subheader("URL ì—…ë¡œë“œ")
    url_input = st.text_area(
        "í•˜ë‚˜ ì´ìƒì˜ URLì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ìž…ë ¥í•˜ì„¸ìš”",
        value="https://www.mobiinside.co.kr/2025/06/27/ai-news-3/\nhttps://namu.wiki/w/%EC%84%B1%EA%B2%BD",
        height=120,
        help="ì˜ˆ: ê° ì¤„ì— 1ê°œ URL",
    )

    st.subheader("íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "PDF / DOCX / TXT / MD / CSV ì§€ì›",
        type=["pdf", "docx", "txt", "md", "csv", "json", "log"],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
    )

    # í¬ë¡¤ë§ ì˜µì…˜
    respect_robots = st.toggle(
        "robots.txt ì¤€ìˆ˜", value=True,
        help="í•´ì œ ì‹œ ì°¨ë‹¨ ê²½ë¡œë„ ì‹œë„í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ì„œë²„ì—ì„œ ê±°ë¶€ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
    )
    use_js_render = st.toggle(
        "JS ë Œë”ë§(Playwright) ì‚¬ìš©", value=False,
        help="CSR íŽ˜ì´ì§€ ëŒ€ì‘. ëŠë¦¬ê³ , í˜¸ìŠ¤íŒ… í™˜ê²½ì— ë”°ë¼ ë™ìž‘í•˜ì§€ ì•Šì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
    )
    js_only_when_needed = st.toggle(
        "ì •ì  ì¶”ì¶œ ì‹¤íŒ¨/ë¶€ì¡± ì‹œì—ë§Œ JS ì‚¬ìš©", value=True
    )

    # ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼
    if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True):
        try:
            urls = [u.strip() for u in url_input.splitlines() if u.strip()]
            url_docs = get_documents_from_urls_robust(
                urls,
                respect_robots=respect_robots,
                use_js_render=use_js_render,
                js_only_when_needed=js_only_when_needed,
            ) if urls else []

            file_docs = get_documents_from_uploaded_files(uploaded_files) if uploaded_files else []

            docs = (url_docs or []) + (file_docs or [])
            st.session_state.docs = docs
            st.session_state.ready_to_analyze = len(docs) > 0

            if not docs:
                st.warning("ë¶ˆëŸ¬ì˜¨ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. URL ë˜ëŠ” íŒŒì¼ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            else:
                st.success(f"{len(docs)}ê°œ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.caption(traceback.format_exc())
            st.session_state.docs = []
            st.session_state.ready_to_analyze = False

    st.divider()

    # ë¶„ì„ í”„ë¡¬í”„íŠ¸
    user_query = st.text_input(
        "ì§ˆë¬¸/ë¶„ì„ ìš”ì²­",
        value="ìš”ì•½ê³¼ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ì•Œë ¤ì¤˜. ì¶œì²˜ë„ í‘œì‹œí•´ì¤˜."
    )

    analyze_clicked = st.button(
        "ë¶„ì„ ì‹œìž‘",
        type="primary",
        use_container_width=True,
        disabled=not st.session_state.ready_to_analyze
    )

# ------------------------------------
# ë³¸ë¬¸ ë ˆì´ì•„ì›ƒ
# ------------------------------------
col_chat, col_right = st.columns([3, 2])

# ì¢Œì¸¡: ëŒ€í™”/ë¶„ì„
with col_chat:
    st.subheader("ëŒ€í™”")
    for m in st.session_state.messages:
        if isinstance(m, HumanMessage):
            st.chat_message("user").write(m.content)
        elif isinstance(m, AIMessage):
            st.chat_message("assistant").write(m.content)
        else:
            role = "assistant" if isinstance(m, dict) and m.get("role") == "assistant" else "user"
            st.chat_message(role).write(str(m))

    if analyze_clicked and st.session_state.ready_to_analyze and st.session_state.docs:
        st.session_state.messages.append(HumanMessage(content=user_query))
        try:
            retriever = get_retriever_from_source(
                documents=st.session_state.docs
            )
            chain = get_conversational_rag_chain(retriever=retriever)

            with st.spinner("ë¶„ì„ ì¤‘..."):
                result = chain.invoke({"question": user_query})

            answer_text = None
            source_docs: List[Document] = []

            if isinstance(result, dict):
                answer_text = result.get("answer") or result.get("output") or result.get("text")
                sd = result.get("source_documents") or result.get("sources") or []
                if isinstance(sd, list):
                    for d in sd:
                        if isinstance(d, Document):
                            source_docs.append(d)
                        elif isinstance(d, dict) and "page_content" in d:
                            md = d.get("metadata", {}) or {}
                            source_docs.append(Document(page_content=d["page_content"], metadata=md))
            elif isinstance(result, str):
                answer_text = result

            if not answer_text:
                answer_text = "ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤."

            st.chat_message("assistant").write(answer_text)
            st.session_state.messages.append(AIMessage(content=answer_text))

            if source_docs:
                st.session_state.docs_for_citation = source_docs
            else:
                st.session_state.docs_for_citation = st.session_state.docs

            st.session_state.ready_to_analyze = False

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            st.caption(traceback.format_exc())
            st.session_state.ready_to_analyze = False

# ìš°ì¸¡: ì†ŒìŠ¤ ë¯¸ë¦¬ë³´ê¸° & ì°¸ê³ /ì¶œì²˜
with col_right:
    st.subheader("ì†ŒìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
    preview_docs = st.session_state.get("docs_for_citation") or st.session_state.docs
    if preview_docs:
        for i, d in enumerate(preview_docs, 1):
            src = (d.metadata or {}).get("source", "")
            title = (d.metadata or {}).get("title", src or f"ë¬¸ì„œ {i}")
            with st.expander(f"[{i}] {title}"):
                if src:
                    st.caption(src)
                body = d.page_content or ""
                st.write(body[:1200] + ("..." if len(body) > 1200 else ""))

    st.subheader("ì°¸ê³ /ì¶œì²˜")
    if preview_docs:
        seen = set()
        for d in preview_docs:
            src = (d.metadata or {}).get("source") or ""
            title = (d.metadata or {}).get("title") or src
            key = (title, src)
            if src and key not in seen:
                seen.add(key)
                st.markdown(f"- [{title}]({src})")
    else:
        st.caption("ë¶ˆëŸ¬ì˜¨ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
