import subprocess
import sys

# Streamlit Cloud í™˜ê²½ì— ë§ëŠ” Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜
# ì‹œìŠ¤í…œ ì¢…ì†ì„±ì€ packages.txtë¡œ ì„¤ì¹˜ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë¸Œë¼ìš°ì €ë§Œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
try:
    subprocess.run(
        # --with-deps ì˜µì…˜ ì œê±°
        [f"{sys.executable}", "-m", "playwright", "install"],
        check=True,
        capture_output=True,
        text=True
    )
except subprocess.CalledProcessError as e:
    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡œê·¸ë¥¼ ëª…í™•í•˜ê²Œ ì¶œë ¥
    print("Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜ ì‹¤íŒ¨. ì—ëŸ¬ ë¡œê·¸:")
    print(e.stdout)
    print(e.stderr)
    raise

import nest_asyncio
nest_asyncio.apply()

import streamlit as st
import time
import json
from RAG.rag_pipeline import get_retriever_from_source
from RAG.chain_builder import get_conversational_rag_chain, get_default_chain

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Advanced RAG Chatbot", page_icon="âš™ï¸")
st.title("âš™ï¸ Advanced RAG Chatbot")
st.markdown(
    """
    **ë³‘ë ¬ í¬ë¡¤ë§**, **ë‹¤ë‹¨ê³„ í•„í„°ë§**, **ë¬¸ì¥ ë‹¨ìœ„ ì¶œì²˜ í‘œì‹œ** ê¸°ëŠ¥ì´ ì ìš©ëœ RAG ì±—ë´‡ì…ë‹ˆë‹¤.
    """
)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•­ìƒ ì¹œì ˆí•˜ê³ , ì •í™•í•œ ì •ë³´ë¥¼ í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì „ë‹¬í•´ì£¼ì„¸ìš”. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µë³€í•  ìˆ˜ ì—†ë‹¤ê³  ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”."

# --- ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.info("LLAMA_CLOUD_API_KEY, GOOGLE_API_KEY, COHERE_API_KEYë¥¼ Streamlit secretsì— ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
    st.divider()
    
    with st.form("persona_form"):
        st.subheader("ğŸ¤– AI í˜ë¥´ì†Œë‚˜ ì„¤ì •")
        system_prompt_input = st.text_area(
            "AIì˜ ì—­í• ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.",
            value=st.session_state.system_prompt,
            height=150
        )
        if st.form_submit_button("í˜ë¥´ì†Œë‚˜ ì ìš©"):
            st.session_state.system_prompt = system_prompt_input
            st.success("í˜ë¥´ì†Œë‚˜ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")

    st.divider()
    
    with st.form("source_form"):
        st.subheader("ğŸ” ë¶„ì„ ëŒ€ìƒ ì„¤ì •")
        url_input = st.text_area("ì›¹ì‚¬ì´íŠ¸ URL (í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥)", placeholder="https://news.google.com\nhttps://blog.google/...")
        
        uploaded_files = st.file_uploader(
            "íŒŒì¼ ì—…ë¡œë“œ (PDF, DOCX ë“±)",
            accept_multiple_files=True,
            type=['pdf', 'docx', 'txt']
        )

        if st.form_submit_button("ë¶„ì„ ì‹œì‘"):
            source_type = "URL" if url_input else "Files" if uploaded_files else None
            source_input = url_input or uploaded_files

            if source_type:
                with st.spinner("ë¬¸ì„œë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ê³  RAG íŒŒì´í”„ë¼ì¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state.retriever = get_retriever_from_source(source_type, source_input)
                
                if st.session_state.retriever:
                    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
                else:
                    st.error("ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë‚˜ URL/íŒŒì¼ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                st.warning("ë¶„ì„í•  URLì„ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    st.divider()
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.experimental_rerun()

# --- ë©”ì¸ ì±„íŒ… í™”ë©´ ---
for message in st.session_state.get("messages", []):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message and message["sources"]:
            with st.expander("ìì„¸í•œ ì¶œì²˜ ë³´ê¸° (ë¬¸ì¥ ë‹¨ìœ„)"):
                for source in message["sources"]:
                    st.markdown(f"**- {source['title']}** ([ë§í¬]({source['url']}))")
                    for sentence in source['sentences']:
                        st.caption(f"    - {sentence}")
                    st.divider()


if user_input := st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    current_system_prompt = st.session_state.system_prompt

    try:
        with st.chat_message("assistant"):
            if st.session_state.retriever:
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    processing_start_time = time.time()
                    
                    # 1. Retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
                    retrieved_docs = st.session_state.retriever.invoke(user_input)
                    
                    # 2. ê°€ì ¸ì˜¨ ë¬¸ì„œë¡œ RAG ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
                    rag_chain = get_conversational_rag_chain(
                        retriever=lambda x: retrieved_docs, # ì´ë¯¸ ê°€ì ¸ì˜¨ ë¬¸ì„œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        system_prompt=current_system_prompt
                    )
                    ai_answer = rag_chain.invoke(user_input)
                    
                    processing_time = time.time() - processing_start_time

                    # --- ìš”ì²­ëœ JSON ì¶œë ¥ í˜•ì‹ì— ë§ê²Œ ì¬êµ¬ì„± ---
                    sources_by_url = {}
                    for doc in retrieved_docs:
                        url = doc.metadata.get("source", "N/A")
                        title = doc.metadata.get("title", "No Title")
                        sentence = doc.page_content

                        if url not in sources_by_url:
                            sources_by_url[url] = {"url": url, "title": title, "sentences": []}
                        sources_by_url[url]["sentences"].append(sentence)
                    
                    final_sources = list(sources_by_url.values())

                    # ìµœì¢… ê²°ê³¼ ê°ì²´
                    response_json = {
                        "answer": ai_answer,
                        "sources": final_sources,
                        "processing_time": f"{processing_time:.2f}ì´ˆ"
                    }

                    # í™”ë©´ì— í‘œì‹œ
                    st.markdown(response_json["answer"])
                    with st.expander("ìì„¸í•œ ì¶œì²˜ ë³´ê¸° (ë¬¸ì¥ ë‹¨ìœ„)"):
                        st.json(response_json) # ë””ë²„ê¹… ë° í™•ì¸ìš©ìœ¼ë¡œ JSON ì „ì²´ ì¶œë ¥
                        for source in response_json["sources"]:
                            st.markdown(f"**- {source['title']}** ([ë§í¬]({source['url']}))")
                            for sentence in source['sentences']:
                                st.caption(f"    - {sentence}")
                            st.divider()

                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": response_json["answer"], 
                        "sources": response_json["sources"]
                    })

            else: # RAG íŒŒì´í”„ë¼ì¸ì´ ì—†ëŠ” ê²½ìš°
                chain = get_default_chain(current_system_prompt)
                ai_answer = st.write_stream(chain.stream({"question": user_input}))
                st.session_state.messages.append(
                    {"role": "assistant", "content": ai_answer, "sources": []}
                )

    except Exception as e:
        error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        st.error(error_message)
        st.session_state.messages.append({"role": "assistant", "content": error_message, "sources": []})
