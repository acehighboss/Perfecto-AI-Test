import subprocess
import sys
import time
import json
import streamlit as st
from langchain_core.messages import HumanMessage

# Streamlit Cloud í™˜ê²½ì— ë§ëŠ” Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜
# ì‹œìŠ¤í…œ ì¢…ì†ì„±ì€ packages.txtë¡œ ì„¤ì¹˜ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë¸Œë¼ìš°ì €ë§Œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
try:
    subprocess.run(
        # --with-deps ì˜µì…˜ ì œê±°
        [f"{sys.executable}", "-m", "playwright", "install"],
        check=True,
        capture_output=True,
        text=True
    )
except subprocess.CalledProcessError as e:
    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡œê·¸ë¥¼ ëª…í™•í•˜ê²Œ ì¶œë ¥
    print("Playwright ë¸Œë¼ìš°ì € ì„¤ì¹˜ ì‹¤íŒ¨. ì—ëŸ¬ ë¡œê·¸:")
    print(e.stdout)
    print(e.stderr)
    raise

import nest_asyncio
nest_asyncio.apply()

import streamlit as st
import time
import json
from RAG.rag_pipeline import get_retriever_from_source
from RAG.graph_builder import get_rag_graph
from RAG.chain_builder import get_default_chain

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Advanced RAG Chatbot", page_icon="âš™ï¸")
st.title("âš™ï¸ Advanced RAG Chatbot")
st.markdown(
    """
    **ì¶”ê°€ ê²€ìƒ‰(Self-Correction)** ê¸°ëŠ¥ì´ ì ìš©ëœ ì—ì´ì „íŠ¸í˜• RAG ì±—ë´‡ì…ë‹ˆë‹¤.
    ë‹µë³€ì— í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´, ìŠ¤ìŠ¤ë¡œ ì§ˆë¬¸ì„ ë°”ê¿” ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []
# â–¼â–¼â–¼ [ìˆ˜ì •] retriever ëŒ€ì‹  graphë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤. â–¼â–¼â–¼
if "graph" not in st.session_state:
    st.session_state.graph = None
if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•­ìƒ ì¹œì ˆí•˜ê³ , ì •í™•í•œ ì •ë³´ë¥¼ í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì „ë‹¬í•´ì£¼ì„¸ìš”. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µë³€í•  ìˆ˜ ì—†ë‹¤ê³  ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”."

# --- ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    with st.form("persona_form"):
        st.subheader("ğŸ¤– AI í˜ë¥´ì†Œë‚˜ ì„¤ì •")
        system_prompt_input = st.text_area(
            "AIì˜ ì—­í• ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.",
            value=st.session_state.system_prompt,
            height=150
        )
        if st.form_submit_button("í˜ë¥´ì†Œë‚˜ ì ìš©"):
            st.session_state.system_prompt = system_prompt_input
            st.success("í˜ë¥´ì†Œë‚˜ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")

    st.divider()
    
    with st.form("source_form"):
        st.subheader("ğŸ” ë¶„ì„ ëŒ€ìƒ ì„¤ì •")
        url_input = st.text_area("ì›¹ì‚¬ì´íŠ¸ URL (í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥)", placeholder="https://news.google.com\nhttps://blog.google/...")
        
        uploaded_files = st.file_uploader(
            "íŒŒì¼ ì—…ë¡œë“œ (PDF, DOCX ë“±)",
            accept_multiple_files=True,
            type=['pdf', 'docx', 'txt']
        )

        if st.form_submit_button("ë¶„ì„ ì‹œì‘"):
            source_type = "URL" if url_input else "Files" if uploaded_files else None
            source_input = url_input or uploaded_files

            if source_type:
                with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  RAG ì›Œí¬í”Œë¡œìš°ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                    # â–¼â–¼â–¼ [ìˆ˜ì •] retrieverë¥¼ ë§Œë“¤ê³ , ì´ë¥¼ ì‚¬ìš©í•´ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. â–¼â–¼â–¼
                    retriever = get_retriever_from_source(source_type, source_input)
                    if retriever:
                        st.session_state.graph = get_rag_graph(retriever, st.session_state.system_prompt)
                        st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
                    else:
                        st.session_state.graph = None
                        st.error("ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë‚˜ URL/íŒŒì¼ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                st.warning("ë¶„ì„í•  URLì„ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

    st.divider()
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

# --- ë©”ì¸ ì±„íŒ… í™”ë©´ ---
for message in st.session_state.get("messages", []):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message and message["sources"]:
            with st.expander("ìì„¸í•œ ì¶œì²˜ ë³´ê¸° (ë¬¸ì¥ ë‹¨ìœ„)"):
                for source in message["sources"]:
                    st.markdown(f"**- {source['title']}** ([ë§í¬]({source['url']}))")
                    for sentence in source['sentences']:
                        st.caption(f"    - {sentence}")
                    st.divider()


if user_input := st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    try:
        with st.chat_message("assistant"):
            # â–¼â–¼â–¼ [ìˆ˜ì •] ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            if st.session_state.graph:
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (í•„ìš”ì‹œ ì¶”ê°€ ê²€ìƒ‰ ìˆ˜í–‰)"):
                    start_time = time.time()
                    
                    # ê·¸ë˜í”„ ì‹¤í–‰ì„ ìœ„í•œ ì…ë ¥ê°’ ì„¤ì •
                    inputs = {"messages": [HumanMessage(content=user_input)]}
                    final_answer = ""
                    final_sources = []

                    # st.write_streamì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ì˜ ì¤‘ê°„ ë° ìµœì¢… ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
                    for output in st.session_state.graph.stream(inputs):
                        for key, value in output.items():
                            if key == "generate": # ìµœì¢… ë‹µë³€ ìƒì„± ë‹¨ê³„
                                final_answer = value.get("generation")
                                final_sources = value.get("documents")

                    st.markdown(final_answer)

                    # ì¶œì²˜ í‘œì‹œ
                    with st.expander("ìì„¸í•œ ì¶œì²˜ ë³´ê¸° (ë¬¸ì¥ ë‹¨ìœ„)"):
                        sources_by_url = {}
                        for doc in final_sources:
                            url = doc.metadata.get("source", "N/A")
                            title = doc.metadata.get("title", "No Title")
                            sentence = doc.page_content

                            if url not in sources_by_url:
                                sources_by_url[url] = {"url": url, "title": title, "sentences": []}
                            sources_by_url[url]["sentences"].append(sentence)
                        
                        final_sources_list = list(sources_by_url.values())
                        for source in final_sources_list:
                            st.markdown(f"**- {source['title']}** ([ë§í¬]({source['url']}))")
                            for sentence in source['sentences']:
                                st.caption(f"    - {sentence}")
                            st.divider()
                    
                    processing_time = time.time() - start_time
                    st.caption(f"ë‹µë³€ ìƒì„± ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {processing_time:.2f}ì´ˆ)")

                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": final_answer,
                        "sources": final_sources_list
                    })

            else: # RAG íŒŒì´í”„ë¼ì¸ì´ ì—†ëŠ” ê²½ìš°
                chain = get_default_chain(current_system_prompt)
                ai_answer = st.write_stream(chain.stream({"question": user_input}))
                st.session_state.messages.append(
                    {"role": "assistant", "content": ai_answer, "sources": []}
                )

    except Exception as e:
        error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        st.error(error_message)
        st.session_state.messages.append({"role": "assistant", "content": error_message, "sources": []})
